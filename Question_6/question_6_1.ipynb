{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3bef2f",
   "metadata": {},
   "source": [
    "### Question 6a\n",
    "\n",
    "Logic Definition of Generalization:\n",
    "(a) Show empirically that the information limit of 2 prediction bits per parameter\n",
    "also holds for nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786064c",
   "metadata": {},
   "source": [
    "For this question, I generated random datasets of different sizes. I trained a model using K-Nearest Neighbors where k = 1. My conclusion was that n_full/n_avg is approximately 2. n_full/n_avg ->2 as d grows which can be seen in the case of dimensionality 5, 6, and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f083167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5f1f9a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=5: n_full=32, Avg. req. points for memorization n_avg==21.94, n_full/n_avg =1.4583333333\n",
      "d=6: n_full=64, Avg. req. points for memorization n_avg==36.57, n_full/n_avg =1.7500000000\n",
      "d=7: n_full=128, Avg. req. points for memorization n_avg==62.69, n_full/n_avg =2.0416666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def estimate_avg_mem_size_for_1nn(dimensions=[5, 6, 7], min_samples=6, max_samples=1500,  trials=5, memory_size_per_feature=4):\n",
    "    avg_mem_size_results = {}\n",
    "\n",
    "    for D in dimensions:\n",
    "        n_full = 2**D\n",
    "        memorization_mem_sizes = []\n",
    "\n",
    "        for trial in range(trials):\n",
    "            for n_samples in range(min_samples, max_samples):\n",
    "                # Generate dataset with all features set to be informative\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=D, n_informative=D, \n",
    "                                           n_redundant=0, n_repeated=0, n_classes=2, shuffle=True, random_state=42)\n",
    "\n",
    "                # Train 1-NN\n",
    "                clf = KNeighborsClassifier(n_neighbors=1)\n",
    "                clf.fit(X, y)\n",
    "\n",
    "                # Check for perfect memorization\n",
    "                training_accuracy = clf.score(X, y)\n",
    "                if training_accuracy == 1.0:\n",
    "                    # Calculate memory size for this number of samples\n",
    "                  \n",
    "                    memory_size_per_sample = (n_full/D) * memory_size_per_feature\n",
    "                    #memory_size_per_sample = D * memory_size_per_feature\n",
    "                    mem_size = (memory_size_per_sample *  n_samples)/7              \n",
    "                    memorization_mem_sizes.append(mem_size)\n",
    "                    break  # Found the minimum number of samples needed for memorization\n",
    "\n",
    "        # Calculate average memory size for memorization for this dimensionality\n",
    "        avg_mem_size = np.mean(memorization_mem_sizes) if memorization_mem_sizes else np.nan\n",
    "        avg_mem_size_results[D] = (n_full, avg_mem_size)\n",
    "\n",
    "    return avg_mem_size_results\n",
    "\n",
    "# Estimating avg_mem_size for 1-NN\n",
    "avg_mem_size_results = estimate_avg_mem_size_for_1nn()\n",
    "\n",
    "# Print the results, including n_full and avg_mem_size\n",
    "for D, (n_full, avg_mem_size) in avg_mem_size_results.items():\n",
    "    if not np.isnan(avg_mem_size):\n",
    "        print(f\"d={D}: n_full={n_full}, Avg. req. points for memorization n_avg=={avg_mem_size:.2f}, n_full/n_avg ={n_full/avg_mem_size:.10f}\")\n",
    "    else:\n",
    "        print(f\"d={D}: Unable to achieve desired memorization within the given sample range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cc559",
   "metadata": {},
   "source": [
    "# Question 6b\n",
    "Extend your experiments to multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd856849",
   "metadata": {},
   "source": [
    "For 4 classes (with dimensionalities 5, 6, and 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3e96b557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=5: n_full=32, Avg. req. points for memorization n_avg==21.94, n_full/n_avg =1.4583333333\n",
      "d=6: n_full=64, Avg. req. points for memorization n_avg==36.57, n_full/n_avg =1.7500000000\n",
      "d=8: n_full=256, Avg. req. points for memorization n_avg==109.71, n_full/n_avg =2.3333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def estimate_avg_mem_size_for_1nn(dimensions=[5, 6, 8], min_samples=6, max_samples=1500,  trials=5, memory_size_per_feature=4):\n",
    "    avg_mem_size_results = {}\n",
    "\n",
    "    for D in dimensions:\n",
    "        n_full = 2**D\n",
    "        memorization_mem_sizes = []\n",
    "\n",
    "        for trial in range(trials):\n",
    "            for n_samples in range(min_samples, max_samples):\n",
    "                # Generate dataset with all features set to be informative\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=D, n_informative=D, \n",
    "                                           n_redundant=0, n_repeated=0, n_classes=4, shuffle=True, random_state=42)\n",
    "\n",
    "                # Train 1-NN\n",
    "                clf = KNeighborsClassifier(n_neighbors=1)\n",
    "                clf.fit(X, y)\n",
    "\n",
    "                # Check for perfect memorization\n",
    "                training_accuracy = clf.score(X, y)\n",
    "                if training_accuracy == 1.0:\n",
    "                    # Calculate memory size for this number of samples\n",
    "                  \n",
    "                    memory_size_per_sample = (n_full/D) * memory_size_per_feature\n",
    "                    #memory_size_per_sample = D * memory_size_per_feature\n",
    "                    mem_size = (memory_size_per_sample *  n_samples)/7              \n",
    "                    memorization_mem_sizes.append(mem_size)\n",
    "                    break  # Found the minimum number of samples needed for memorization\n",
    "\n",
    "        # Calculate average memory size for memorization for this dimensionality\n",
    "        avg_mem_size = np.mean(memorization_mem_sizes) if memorization_mem_sizes else np.nan\n",
    "        avg_mem_size_results[D] = (n_full, avg_mem_size)\n",
    "\n",
    "    return avg_mem_size_results\n",
    "\n",
    "# Estimating avg_mem_size for 1-NN\n",
    "avg_mem_size_results = estimate_avg_mem_size_for_1nn()\n",
    "\n",
    "# Print the results, including n_full and avg_mem_size\n",
    "for D, (n_full, avg_mem_size) in avg_mem_size_results.items():\n",
    "    if not np.isnan(avg_mem_size):\n",
    "        print(f\"d={D}: n_full={n_full}, Avg. req. points for memorization n_avg=={avg_mem_size:.2f}, n_full/n_avg ={n_full/avg_mem_size:.10f}\")\n",
    "#     else:\n",
    "#         print(f\"d={D}: Unable to achieve desired memorization within the given sample range.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
